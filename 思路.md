处理过程主要分为两部分：文本检索与答案抽取
1.文本检索：
这部分的代码主要在retrieve.py文件中，步骤如下：
- 统计除文本中的所有词语，利用gensim构建字典
- 遍历所有文档，计算词典中所有词语的idf
- 利用log(1 + tf) x idf 计算词语的idf权重,并将文档投射到tfidf向量空间中
- 计算每一个问句向量和所有文章向量的余弦相似度，返回最相似的文档

2.答案抽取
此部分的实现主要在get_answert.py中，步骤如下：
- 匹配疑问词，将问题分成5个类别，见question_classify.py
- 从 问题-文章 相似度列表中返回前五个最相似的文档
- 对文档进行分句，并通过tfidf相似度匹配出最相似的句子，见rate_entities.py中的rate_sentence
- 以逗号分隔，再次调用rate_sentence对逗号分隔的部分进行相似度计算，返回最相似的部分
- 借助stanford的NER工具对最匹配部分的句子进行尸体明明标注**这里有个坑还没有解决：下载了stanford的NER包后貌似不能标注出日期（DATE)和数字（NUMBER)导致部分答案无法抽取**
- 从标注好的句子中抽取符合问题类型的实体，加入候选实体列表
- 将问句中的疑问词替换成实提列表中的词（见rate_entities.py中的replace_interrogative方法）
- 抽取最匹配的实体（见rate_entities.py中的ratin_entities方法），比较过程如下：
	 -  遍历候选实体列表，先判断实体有没有在问题中出现过（若有就先去掉，以免抽取出和问题相同的无意义的实体--is_duplicate方法）【判断是否为重复实体采用jarcard系数**这里又有另外一个bug：其中一个问题提到了‘海尔集团’，由于分词器的效果问题，没有将词语断开，导致在计算相似度时不能很好地区分问题中的实体是否与文档中的重复，直接影响到了答案的准确性**】
   -  将问句中的疑问词替换成实体，并构造一个新的问句向量，通过新问句向量与原问句向量相似性的比较，选出最佳实体作为答案，==> 返回结果
